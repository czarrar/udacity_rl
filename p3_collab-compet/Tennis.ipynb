{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Tennis.app\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agents and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agents' performance, if they select actions at random with each time step.  A window should pop up that allows you to observe the agents.\n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agents are able to use their experiences to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (max over agents) from episode 1: 0.0\n",
      "Score (max over agents) from episode 2: 0.0\n",
      "Score (max over agents) from episode 3: 0.09000000171363354\n",
      "Score (max over agents) from episode 4: 0.10000000149011612\n",
      "Score (max over agents) from episode 5: 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 6):                                      # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Score (max over agents) from episode {}: {}'.format(i, np.max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "#from workspace_utils import keep_awake\n",
    "\n",
    "from maddpg import MAgent\n",
    "from importlib import reload\n",
    "import maddpg\n",
    "maddpg = reload(maddpg)\n",
    "MAgent = maddpg.MAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ddpg_multi(agent, n_episodes=5000, queue=100, print_every=50):        \n",
    "    \"\"\"Multi Deep Deterministic Policy Gradient learning for Tennis Unity Environment.\n",
    "    \n",
    "    Params Input\n",
    "    ==========\n",
    "        agent (MAgent): The agent class\n",
    "        n_episode (int): maximum number of episodes\n",
    "        queue (int): number of consecutive episodes to average up\n",
    "        print_every (int): frequency of printing information throughout iteration.\n",
    "        \n",
    "    Params Output\n",
    "    ==========\n",
    "        scores_all (list of floats): are the scores collected at the end of each episode\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    ##Inizialization\n",
    "    scores_window = deque(maxlen=queue)     \n",
    "    scores_all = []        \n",
    "    moving_avgs = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]      \n",
    "        states = env_info.vector_observations\n",
    "        agent.reset()\n",
    "        scores = np.zeros(2)\n",
    "        \n",
    "        ## Training loop of each episode\n",
    "        while True:\n",
    "            actions = agent.act(states, add_noise=True)\n",
    "            env_info = env.step(actions)[brain_name]           \n",
    "            next_states = env_info.vector_observations         \n",
    "            rewards = env_info.rewards                         \n",
    "            dones = env_info.local_done\n",
    "            agent.step(states, actions, rewards, next_states, dones)\n",
    "            scores += rewards                                  \n",
    "            states = next_states                               \n",
    "            if np.any(dones):                                  \n",
    "                break\n",
    "\n",
    "        scores_window.append(np.max(scores)) # take the max of the two agents\n",
    "        scores_all.append(np.max(scores))\n",
    "        \n",
    "        moving_avg = np.mean(scores_window)  # calculate moving average\n",
    "        moving_avgs.append(moving_avg)       # save most recent moving average\n",
    "        \n",
    "        #print('Episode {} ## Reward 1 agent: {:.3f} ##  Reward 2 : {:.3f} ## Max: {:.3f} ## Average: {:.2f}'.format(\n",
    "        #        i_episode, scores[0], scores[1], np.max(scores), np.mean(scores_window)), end=\"\")\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        \n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        \n",
    "        if np.mean(scores_window)>=0.5 and i_episode >= queue:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.3f}'.format(\n",
    "                i_episode, np.mean(scores_window)))\n",
    "            torch.save(agent.agents[0].actor_local.state_dict(), 'checkpoint_actor0.pth')\n",
    "            torch.save(agent.agents[0].critic_local.state_dict(), 'checkpoint_critic0.pth')\n",
    "            torch.save(agent.agents[1].actor_local.state_dict(), 'checkpoint_actor1.pth')\n",
    "            torch.save(agent.agents[1].critic_local.state_dict(), 'checkpoint_critic1.pth')\n",
    "            break\n",
    "\n",
    "    return scores_all, moving_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50\tAverage Score: 0.00\n",
      "Episode 100\tAverage Score: 0.01\n",
      "Episode 150\tAverage Score: 0.04\n",
      "Episode 200\tAverage Score: 0.07\n",
      "Episode 250\tAverage Score: 0.10\n",
      "Episode 300\tAverage Score: 0.12\n",
      "Episode 350\tAverage Score: 0.14\n",
      "Episode 400\tAverage Score: 0.21\n",
      "Episode 450\tAverage Score: 0.23\n",
      "Episode 500\tAverage Score: 0.22\n",
      "Episode 550\tAverage Score: 0.29\n",
      "Episode 600\tAverage Score: 0.34\n",
      "Episode 650\tAverage Score: 0.33\n",
      "Episode 700\tAverage Score: 0.30\n",
      "Episode 750\tAverage Score: 0.33\n",
      "Episode 800\tAverage Score: 0.46\n",
      "Episode 816\tAverage Score: 0.51\n",
      "Environment solved in 816 episodes!\tAverage Score: 0.506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.20000000298023224,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.20000000298023224,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.39000000804662704,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.20000000298023224,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.1900000050663948,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.19000000320374966,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.30000000447034836,\n",
       "  0.20000000298023224,\n",
       "  0.4000000059604645,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.4000000059604645,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.19000000320374966,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.5000000074505806,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000357627869,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.19000000320374966,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.4000000059604645,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.3900000061839819,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  0.19000000320374966,\n",
       "  0.0,\n",
       "  0.19000000320374966,\n",
       "  0.20000000298023224,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.30000000447034836,\n",
       "  0.0,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  0.4000000059604645,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.30000000447034836,\n",
       "  0.30000000447034836,\n",
       "  0.4000000059604645,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.490000007674098,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.19000000320374966,\n",
       "  0.30000000447034836,\n",
       "  0.6900000106543303,\n",
       "  0.4000000059604645,\n",
       "  0.30000000447034836,\n",
       "  0.4000000059604645,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.30000000447034836,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.7000000104308128,\n",
       "  0.20000000298023224,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.7000000104308128,\n",
       "  0.490000007674098,\n",
       "  0.0,\n",
       "  0.800000011920929,\n",
       "  0.19000000320374966,\n",
       "  0.4000000059604645,\n",
       "  0.30000000447034836,\n",
       "  0.9000000134110451,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.4000000059604645,\n",
       "  0.30000000447034836,\n",
       "  0.20000000298023224,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.6000000089406967,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.4000000059604645,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.30000000447034836,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.9000000134110451,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.4000000059604645,\n",
       "  0.19000000320374966,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.30000000447034836,\n",
       "  0.20000000298023224,\n",
       "  0.4000000059604645,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.4000000059604645,\n",
       "  0.20000000298023224,\n",
       "  0.1900000050663948,\n",
       "  0.7000000104308128,\n",
       "  0.10000000149011612,\n",
       "  0.2900000046938658,\n",
       "  0.5000000074505806,\n",
       "  0.19000000320374966,\n",
       "  0.10000000149011612,\n",
       "  0.4000000059604645,\n",
       "  0.10000000149011612,\n",
       "  0.4000000059604645,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.2900000046938658,\n",
       "  0.30000000447034836,\n",
       "  0.3900000061839819,\n",
       "  0.30000000447034836,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.30000000447034836,\n",
       "  0.0,\n",
       "  0.5000000074505806,\n",
       "  0.490000007674098,\n",
       "  0.10000000149011612,\n",
       "  0.5900000091642141,\n",
       "  0.20000000298023224,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.490000007674098,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.19000000320374966,\n",
       "  0.10000000149011612,\n",
       "  0.30000000447034836,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.6000000089406967,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.19000000320374966,\n",
       "  0.4000000059604645,\n",
       "  0.30000000447034836,\n",
       "  0.5000000074505806,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.30000000447034836,\n",
       "  0.6000000089406967,\n",
       "  0.30000000447034836,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.490000007674098,\n",
       "  1.5000000223517418,\n",
       "  0.30000000447034836,\n",
       "  0.6000000089406967,\n",
       "  0.5000000074505806,\n",
       "  0.30000000447034836,\n",
       "  0.5000000074505806,\n",
       "  0.0,\n",
       "  0.30000000447034836,\n",
       "  0.3900000061839819,\n",
       "  0.30000000447034836,\n",
       "  0.19000000320374966,\n",
       "  0.20000000298023224,\n",
       "  0.3900000061839819,\n",
       "  0.5900000091642141,\n",
       "  0.6000000089406967,\n",
       "  0.7000000104308128,\n",
       "  0.4000000059604645,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.30000000447034836,\n",
       "  0.30000000447034836,\n",
       "  0.20000000298023224,\n",
       "  0.3900000061839819,\n",
       "  0.9000000134110451,\n",
       "  0.30000000447034836,\n",
       "  0.5000000074505806,\n",
       "  0.30000000447034836,\n",
       "  0.4000000059604645,\n",
       "  0.10000000149011612,\n",
       "  0.5000000074505806,\n",
       "  0.4000000059604645,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.30000000447034836,\n",
       "  0.5000000074505806,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5000000074505806,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000357627869,\n",
       "  0.4000000059604645,\n",
       "  0.490000007674098,\n",
       "  0.0,\n",
       "  0.30000000447034836,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.490000007674098,\n",
       "  0.9900000151246786,\n",
       "  0.5000000074505806,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.6000000089406967,\n",
       "  0.5000000074505806,\n",
       "  0.6000000089406967,\n",
       "  0.10000000149011612,\n",
       "  0.6000000089406967,\n",
       "  1.0000000149011612,\n",
       "  0.3900000061839819,\n",
       "  0.30000000447034836,\n",
       "  0.6000000089406967,\n",
       "  0.30000000447034836,\n",
       "  0.30000000447034836,\n",
       "  0.09000000171363354,\n",
       "  0.20000000298023224,\n",
       "  0.30000000447034836,\n",
       "  0.30000000447034836,\n",
       "  0.19000000320374966,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.4000000059604645,\n",
       "  0.5000000074505806,\n",
       "  0.6000000089406967,\n",
       "  0.30000000447034836,\n",
       "  0.20000000298023224,\n",
       "  1.0000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.6900000106543303,\n",
       "  0.19000000320374966,\n",
       "  1.5000000223517418,\n",
       "  0.0,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.6000000089406967,\n",
       "  0.0,\n",
       "  0.20000000298023224,\n",
       "  0.20000000298023224,\n",
       "  0.7000000104308128,\n",
       "  0.0,\n",
       "  0.3900000061839819,\n",
       "  0.4000000059604645,\n",
       "  0.0,\n",
       "  0.4000000059604645,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.30000000447034836,\n",
       "  0.2900000046938658,\n",
       "  0.6000000089406967,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.5900000110268593,\n",
       "  0.5000000074505806,\n",
       "  0.6000000089406967,\n",
       "  0.20000000298023224,\n",
       "  0.7900000121444464,\n",
       "  0.09000000171363354,\n",
       "  0.30000000447034836,\n",
       "  0.20000000298023224,\n",
       "  0.5000000074505806,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.4000000059604645,\n",
       "  0.5000000074505806,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.4000000059604645,\n",
       "  0.800000011920929,\n",
       "  1.1900000181049109,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.6900000106543303,\n",
       "  0.0,\n",
       "  0.5000000074505806,\n",
       "  0.4000000059604645,\n",
       "  0.20000000298023224,\n",
       "  0.20000000298023224,\n",
       "  0.20000000298023224,\n",
       "  0.19000000320374966,\n",
       "  0.2900000046938658,\n",
       "  0.10000000149011612,\n",
       "  0.7000000104308128,\n",
       "  0.9000000134110451,\n",
       "  0.30000000447034836,\n",
       "  0.4000000059604645,\n",
       "  0.5000000074505806,\n",
       "  0.2900000046938658,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.6000000089406967,\n",
       "  0.19000000320374966,\n",
       "  0.5900000091642141,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  0.5000000074505806,\n",
       "  0.0,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.30000000447034836,\n",
       "  0.0,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.20000000298023224,\n",
       "  0.4000000059604645,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.7000000104308128,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.19000000320374966,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.9000000134110451,\n",
       "  0.5000000074505806,\n",
       "  1.1000000163912773,\n",
       "  0.19000000320374966,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.4000000059604645,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.4000000059604645,\n",
       "  0.6000000089406967,\n",
       "  0.0,\n",
       "  0.5000000074505806,\n",
       "  0.4000000059604645,\n",
       "  0.5000000074505806,\n",
       "  0.20000000298023224,\n",
       "  0.2900000046938658,\n",
       "  0.0,\n",
       "  0.20000000298023224,\n",
       "  0.800000011920929,\n",
       "  0.4000000059604645,\n",
       "  0.10000000149011612,\n",
       "  0.5000000074505806,\n",
       "  0.4000000059604645,\n",
       "  0.30000000447034836,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.7000000104308128,\n",
       "  0.5900000091642141,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.5900000091642141,\n",
       "  1.2000000178813934,\n",
       "  0.30000000447034836,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  1.8000000268220901,\n",
       "  0.30000000447034836,\n",
       "  0.30000000447034836,\n",
       "  1.5900000240653753,\n",
       "  0.4000000059604645,\n",
       "  0.30000000447034836,\n",
       "  0.9000000134110451,\n",
       "  0.30000000447034836,\n",
       "  0.0,\n",
       "  0.5000000074505806,\n",
       "  0.20000000298023224,\n",
       "  0.5000000074505806,\n",
       "  0.5000000074505806,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.6000000089406967,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.7000000104308128,\n",
       "  0.0,\n",
       "  0.4000000059604645,\n",
       "  0.30000000447034836,\n",
       "  0.4000000059604645,\n",
       "  0.7000000104308128,\n",
       "  0.5900000091642141,\n",
       "  0.20000000298023224,\n",
       "  0.30000000447034836,\n",
       "  0.0,\n",
       "  0.7000000104308128,\n",
       "  1.1000000163912773,\n",
       "  0.20000000298023224,\n",
       "  0.6000000089406967,\n",
       "  0.20000000298023224,\n",
       "  0.800000011920929,\n",
       "  0.4000000059604645,\n",
       "  0.20000000298023224,\n",
       "  0.7000000104308128,\n",
       "  1.2000000178813934,\n",
       "  0.10000000149011612,\n",
       "  1.5000000223517418,\n",
       "  1.1000000163912773,\n",
       "  0.30000000447034836,\n",
       "  0.4000000059604645,\n",
       "  0.5000000074505806,\n",
       "  0.5000000074505806,\n",
       "  0.30000000447034836,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.4000000059604645,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.20000000298023224,\n",
       "  0.09000000171363354,\n",
       "  0.7000000104308128,\n",
       "  0.7000000104308128,\n",
       "  0.20000000298023224,\n",
       "  0.30000000447034836,\n",
       "  1.9000000283122063,\n",
       "  0.4000000059604645,\n",
       "  2.600000038743019,\n",
       "  0.10000000149011612,\n",
       "  2.600000038743019,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  1.1000000163912773,\n",
       "  0.9000000134110451,\n",
       "  0.6000000089406967,\n",
       "  0.5000000074505806,\n",
       "  0.5000000074505806,\n",
       "  0.10000000149011612,\n",
       "  1.4000000208616257,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.7000000104308128,\n",
       "  0.19000000320374966,\n",
       "  0.19000000320374966,\n",
       "  1.5000000223517418,\n",
       "  1.0000000149011612],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.008333333457509676,\n",
       "  0.007692307806932009,\n",
       "  0.007142857249294009,\n",
       "  0.0066666667660077415,\n",
       "  0.0062500000931322575,\n",
       "  0.00588235302883036,\n",
       "  0.005555555638339784,\n",
       "  0.005263157973164006,\n",
       "  0.005000000074505806,\n",
       "  0.004761904832862672,\n",
       "  0.004545454613187097,\n",
       "  0.004347826151744179,\n",
       "  0.004166666728754838,\n",
       "  0.004000000059604645,\n",
       "  0.0038461539034660044,\n",
       "  0.0037037037588931896,\n",
       "  0.0035714286246470044,\n",
       "  0.00344827591345228,\n",
       "  0.0033333333830038708,\n",
       "  0.0032258064996811653,\n",
       "  0.0031250000465661287,\n",
       "  0.003030303075458064,\n",
       "  0.00294117651441518,\n",
       "  0.0028571428997176034,\n",
       "  0.002777777819169892,\n",
       "  0.002702702742976111,\n",
       "  0.002631578986582003,\n",
       "  0.0025641026023106696,\n",
       "  0.002500000037252903,\n",
       "  0.002439024426588198,\n",
       "  0.002380952416431336,\n",
       "  0.0023255814300027003,\n",
       "  0.0022727273065935483,\n",
       "  0.0022222222553359137,\n",
       "  0.0021739130758720894,\n",
       "  0.0021276596061726833,\n",
       "  0.002083333364377419,\n",
       "  0.0020408163569411455,\n",
       "  0.004000000059604645,\n",
       "  0.003921568685886907,\n",
       "  0.0038461539034660044,\n",
       "  0.0056603774428367615,\n",
       "  0.007407407517786379,\n",
       "  0.007272727381099354,\n",
       "  0.007142857249294009,\n",
       "  0.007017543964218675,\n",
       "  0.00689655182690456,\n",
       "  0.0067796611179739745,\n",
       "  0.0066666667660077415,\n",
       "  0.00655737714689286,\n",
       "  0.0064516129993623305,\n",
       "  0.006349206443816897,\n",
       "  0.0062500000931322575,\n",
       "  0.006153846245545607,\n",
       "  0.006060606150916128,\n",
       "  0.0059701493426934996,\n",
       "  0.00588235302883036,\n",
       "  0.005797101535658905,\n",
       "  0.007142857249294009,\n",
       "  0.008450704351277418,\n",
       "  0.008333333457509676,\n",
       "  0.008219178204667079,\n",
       "  0.008108108228928334,\n",
       "  0.00800000011920929,\n",
       "  0.00921052645303701,\n",
       "  0.009090909226374193,\n",
       "  0.01012820528390316,\n",
       "  0.01000000015372717,\n",
       "  0.00987500015180558,\n",
       "  0.009753086569684523,\n",
       "  0.009634146489566418,\n",
       "  0.009518072435475257,\n",
       "  0.010476190641167619,\n",
       "  0.010352941339506823,\n",
       "  0.010232558300675348,\n",
       "  0.011264367992508,\n",
       "  0.011136363810774956,\n",
       "  0.012134831649868677,\n",
       "  0.012000000187092357,\n",
       "  0.012857143061010393,\n",
       "  0.012717391505999409,\n",
       "  0.01258064536077361,\n",
       "  0.012446808707999421,\n",
       "  0.012315789668967849,\n",
       "  0.012187500193249434,\n",
       "  0.012061855861360264,\n",
       "  0.01193877569950965,\n",
       "  0.012727272931975548,\n",
       "  0.013600000217556953,\n",
       "  0.014500000234693288,\n",
       "  0.014500000234693288,\n",
       "  0.01550000024959445,\n",
       "  0.016400000266730785,\n",
       "  0.016400000266730785,\n",
       "  0.016400000266730785,\n",
       "  0.018400000296533107,\n",
       "  0.018400000296533107,\n",
       "  0.018400000296533107,\n",
       "  0.018400000296533107,\n",
       "  0.018400000296533107,\n",
       "  0.018400000296533107,\n",
       "  0.018400000296533107,\n",
       "  0.019400000311434268,\n",
       "  0.019400000311434268,\n",
       "  0.019400000311434268,\n",
       "  0.02040000032633543,\n",
       "  0.02040000032633543,\n",
       "  0.02040000032633543,\n",
       "  0.02140000034123659,\n",
       "  0.02140000034123659,\n",
       "  0.02140000034123659,\n",
       "  0.02240000035613775,\n",
       "  0.02240000035613775,\n",
       "  0.023400000371038912,\n",
       "  0.023400000371038912,\n",
       "  0.023400000371038912,\n",
       "  0.024400000385940077,\n",
       "  0.025400000400841238,\n",
       "  0.026300000417977573,\n",
       "  0.026300000417977573,\n",
       "  0.026300000417977573,\n",
       "  0.028300000447779895,\n",
       "  0.028300000447779895,\n",
       "  0.028300000447779895,\n",
       "  0.029300000462681056,\n",
       "  0.030300000477582217,\n",
       "  0.031300000492483375,\n",
       "  0.03230000050738454,\n",
       "  0.03230000050738454,\n",
       "  0.0333000005222857,\n",
       "  0.03430000053718686,\n",
       "  0.03530000055208802,\n",
       "  0.036300000566989184,\n",
       "  0.03730000058189034,\n",
       "  0.03730000058189034,\n",
       "  0.03730000058189034,\n",
       "  0.03730000058189034,\n",
       "  0.038300000596791506,\n",
       "  0.03730000058189034,\n",
       "  0.03730000058189034,\n",
       "  0.038300000596791506,\n",
       "  0.03820000059902668,\n",
       "  0.03820000059902668,\n",
       "  0.03920000061392784,\n",
       "  0.040200000628829,\n",
       "  0.044100000709295276,\n",
       "  0.044100000709295276,\n",
       "  0.04510000072419643,\n",
       "  0.04600000074133277,\n",
       "  0.046900000758469104,\n",
       "  0.046900000758469104,\n",
       "  0.04780000077560544,\n",
       "  0.049800000805407765,\n",
       "  0.0507000008225441,\n",
       "  0.05170000083744526,\n",
       "  0.05270000085234642,\n",
       "  0.053700000867247584,\n",
       "  0.054600000884383916,\n",
       "  0.05360000086948276,\n",
       "  0.05350000087171793,\n",
       "  0.05450000088661909,\n",
       "  0.05750000093132258,\n",
       "  0.058500000946223735,\n",
       "  0.0595000009611249,\n",
       "  0.058500000946223735,\n",
       "  0.0595000009611249,\n",
       "  0.05860000094398856,\n",
       "  0.059600000958889725,\n",
       "  0.06060000097379088,\n",
       "  0.06160000098869205,\n",
       "  0.06260000100359321,\n",
       "  0.06360000101849436,\n",
       "  0.06360000101849436,\n",
       "  0.06460000103339553,\n",
       "  0.06460000103339553,\n",
       "  0.06360000101849436,\n",
       "  0.06450000103563071,\n",
       "  0.06540000107139349,\n",
       "  0.06630000108852982,\n",
       "  0.06540000107139349,\n",
       "  0.06540000107139349,\n",
       "  0.06640000108629465,\n",
       "  0.06730000110343098,\n",
       "  0.06820000112056732,\n",
       "  0.06910000113770366,\n",
       "  0.06910000113770366,\n",
       "  0.07010000115260481,\n",
       "  0.07020000115036965,\n",
       "  0.07020000115036965,\n",
       "  0.07030000114813446,\n",
       "  0.07120000116527081,\n",
       "  0.07020000115036965,\n",
       "  0.06930000113323331,\n",
       "  0.07030000114813446,\n",
       "  0.07130000116303563,\n",
       "  0.07030000114813446,\n",
       "  0.07130000116303563,\n",
       "  0.07320000119507312,\n",
       "  0.07320000119507312,\n",
       "  0.07420000120997429,\n",
       "  0.07420000120997429,\n",
       "  0.07510000122711062,\n",
       "  0.07510000122711062,\n",
       "  0.07610000124201179,\n",
       "  0.07700000125914812,\n",
       "  0.07700000125914812,\n",
       "  0.07800000127404928,\n",
       "  0.07900000128895045,\n",
       "  0.0800000013038516,\n",
       "  0.08100000131875276,\n",
       "  0.08200000133365393,\n",
       "  0.0819000013358891,\n",
       "  0.08280000135302544,\n",
       "  0.08280000135302544,\n",
       "  0.08380000136792659,\n",
       "  0.08480000138282776,\n",
       "  0.08470000138506294,\n",
       "  0.08370000137016177,\n",
       "  0.08380000136792659,\n",
       "  0.08470000138506294,\n",
       "  0.08570000139996409,\n",
       "  0.08470000138506294,\n",
       "  0.08570000139996409,\n",
       "  0.08670000141486525,\n",
       "  0.08670000141486525,\n",
       "  0.08670000141486525,\n",
       "  0.08870000144466758,\n",
       "  0.08970000145956875,\n",
       "  0.09370000151917339,\n",
       "  0.09370000151917339,\n",
       "  0.09370000151917339,\n",
       "  0.09370000151917339,\n",
       "  0.09370000151917339,\n",
       "  0.09470000153407454,\n",
       "  0.0957000015489757,\n",
       "  0.09670000156387687,\n",
       "  0.0976000015810132,\n",
       "  0.0976000015810132,\n",
       "  0.10160000164061785,\n",
       "  0.10360000167042017,\n",
       "  0.10360000167042017,\n",
       "  0.103700001668185,\n",
       "  0.10470000168308616,\n",
       "  0.10570000169798732,\n",
       "  0.10570000169798732,\n",
       "  0.10380000164732336,\n",
       "  0.10480000166222453,\n",
       "  0.10480000166222453,\n",
       "  0.10490000165998936,\n",
       "  0.10400000164285302,\n",
       "  0.10500000165775418,\n",
       "  0.10600000167265534,\n",
       "  0.10500000165775418,\n",
       "  0.10510000165551901,\n",
       "  0.10610000167042016,\n",
       "  0.11010000173002482,\n",
       "  0.11010000173002482,\n",
       "  0.11020000172778964,\n",
       "  0.1112000017426908,\n",
       "  0.11230000175535679,\n",
       "  0.11220000175759197,\n",
       "  0.11020000172778964,\n",
       "  0.1112000017426908,\n",
       "  0.1112000017426908,\n",
       "  0.11220000175759197,\n",
       "  0.11220000175759197,\n",
       "  0.11320000177249312,\n",
       "  0.11320000177249312,\n",
       "  0.11310000179335475,\n",
       "  0.11310000179335475,\n",
       "  0.11310000179335475,\n",
       "  0.11310000179335475,\n",
       "  0.11420000180602073,\n",
       "  0.1152000018209219,\n",
       "  0.11620000183582306,\n",
       "  0.11820000186562538,\n",
       "  0.11820000186562538,\n",
       "  0.11720000183209776,\n",
       "  0.1173000018298626,\n",
       "  0.11820000184699893,\n",
       "  0.11920000186190009,\n",
       "  0.11920000186190009,\n",
       "  0.11930000185966491,\n",
       "  0.12040000187233091,\n",
       "  0.12050000187009573,\n",
       "  0.12150000188499689,\n",
       "  0.12150000188499689,\n",
       "  0.12240000190213322,\n",
       "  0.12340000191703439,\n",
       "  0.12340000191703439,\n",
       "  0.1265000019595027,\n",
       "  0.12750000197440386,\n",
       "  0.12850000198930503,\n",
       "  0.12850000198930503,\n",
       "  0.1314000020362437,\n",
       "  0.133400002066046,\n",
       "  0.133400002066046,\n",
       "  0.133400002066046,\n",
       "  0.133400002066046,\n",
       "  0.13430000208318232,\n",
       "  0.1353000020980835,\n",
       "  0.13440000208094716,\n",
       "  0.13440000208094716,\n",
       "  0.13440000208094716,\n",
       "  0.134500002078712,\n",
       "  0.134500002078712,\n",
       "  0.134500002078712,\n",
       "  0.13350000206381082,\n",
       "  0.13250000204890966,\n",
       "  0.134500002078712,\n",
       "  0.13350000206381082,\n",
       "  0.13560000209137799,\n",
       "  0.1357000020891428,\n",
       "  0.13870000213384628,\n",
       "  0.13770000211894512,\n",
       "  0.1376000021211803,\n",
       "  0.13770000211894512,\n",
       "  0.13970000214874745,\n",
       "  0.1407000021636486,\n",
       "  0.14080000216141342,\n",
       "  0.14080000216141342,\n",
       "  0.14180000217631458,\n",
       "  0.14180000217631458,\n",
       "  0.14280000219121575,\n",
       "  0.14280000219121575,\n",
       "  0.14480000222101808,\n",
       "  0.14480000222101808,\n",
       "  0.1468000022508204,\n",
       "  0.1438000022061169,\n",
       "  0.1438000022061169,\n",
       "  0.14770000226795674,\n",
       "  0.14770000226795674,\n",
       "  0.14770000226795674,\n",
       "  0.14670000225305557,\n",
       "  0.14670000225305557,\n",
       "  0.14670000225305557,\n",
       "  0.1468000022508204,\n",
       "  0.1468000022508204,\n",
       "  0.1438000022061169,\n",
       "  0.1438000022061169,\n",
       "  0.14580000223591924,\n",
       "  0.14580000223591924,\n",
       "  0.14480000222101808,\n",
       "  0.1438000022061169,\n",
       "  0.1438000022061169,\n",
       "  0.14280000219121575,\n",
       "  0.14280000219121575,\n",
       "  0.14280000219121575,\n",
       "  0.14370000220835208,\n",
       "  0.14670000225305557,\n",
       "  0.15260000234469773,\n",
       "  0.15470000237226486,\n",
       "  0.1567000024020672,\n",
       "  0.15970000244677066,\n",
       "  0.15870000243186952,\n",
       "  0.15570000238716603,\n",
       "  0.15570000238716603,\n",
       "  0.15570000238716603,\n",
       "  0.15570000238716603,\n",
       "  0.1567000024020672,\n",
       "  0.15880000242963432,\n",
       "  0.15880000242963432,\n",
       "  0.15880000242963432,\n",
       "  0.15880000242963432,\n",
       "  0.15880000242963432,\n",
       "  0.1648000025190413,\n",
       "  0.16580000253394245,\n",
       "  0.1648000025190413,\n",
       "  0.16490000249817968,\n",
       "  0.17090000258758664,\n",
       "  0.17480000264942647,\n",
       "  0.1738000026345253,\n",
       "  0.17980000272393226,\n",
       "  0.17970000272616743,\n",
       "  0.18270000277087092,\n",
       "  0.1837000027857721,\n",
       "  0.1918000029027462,\n",
       "  0.19290000291541218,\n",
       "  0.19290000291541218,\n",
       "  0.193000002913177,\n",
       "  0.193000002913177,\n",
       "  0.1960000029578805,\n",
       "  0.19800000298768283,\n",
       "  0.19800000298768283,\n",
       "  0.2010000030323863,\n",
       "  0.2040000030770898,\n",
       "  0.2090000031515956,\n",
       "  0.20810000313445925,\n",
       "  0.2071000031195581,\n",
       "  0.2071000031195581,\n",
       "  0.20410000307485462,\n",
       "  0.2071000031195581,\n",
       "  0.2071000031195581,\n",
       "  0.20810000313445925,\n",
       "  0.20420000307261943,\n",
       "  0.20220000304281713,\n",
       "  0.20320000305771826,\n",
       "  0.20230000304058193,\n",
       "  0.20530000308528543,\n",
       "  0.20340000305324793,\n",
       "  0.20240000303834677,\n",
       "  0.2044000030681491,\n",
       "  0.2044000030681491,\n",
       "  0.21240000318735838,\n",
       "  0.21340000320225955,\n",
       "  0.21340000320225955,\n",
       "  0.216400003246963,\n",
       "  0.2183000032790005,\n",
       "  0.2183000032790005,\n",
       "  0.2163000032491982,\n",
       "  0.21730000326409937,\n",
       "  0.21530000323429704,\n",
       "  0.2163000032491982,\n",
       "  0.21530000323429704,\n",
       "  0.2163000032491982,\n",
       "  0.216400003246963,\n",
       "  0.21840000327676534,\n",
       "  0.21840000327676534,\n",
       "  0.22040000330656767,\n",
       "  0.22040000330656767,\n",
       "  0.22140000332146884,\n",
       "  0.22040000330656767,\n",
       "  0.22340000335127116,\n",
       "  0.22340000335127116,\n",
       "  0.22430000338703393,\n",
       "  0.2283000034466386,\n",
       "  0.22630000341683626,\n",
       "  0.22520000340417026,\n",
       "  0.22920000346377492,\n",
       "  0.23010000348091125,\n",
       "  0.22620000341907143,\n",
       "  0.22920000346377492,\n",
       "  0.22920000346377492,\n",
       "  0.23220000350847841,\n",
       "  0.23120000349357725,\n",
       "  0.23120000349357725,\n",
       "  0.23220000350847841,\n",
       "  0.23220000350847841,\n",
       "  0.23120000349357725,\n",
       "  0.23210000351071358,\n",
       "  0.23210000351071358,\n",
       "  0.23500000355765224,\n",
       "  0.23700000358745454,\n",
       "  0.2360000035725534,\n",
       "  0.2360000035725534,\n",
       "  0.23500000355765224,\n",
       "  0.23500000355765224,\n",
       "  0.2380000036023557,\n",
       "  0.24010000362992287,\n",
       "  0.23810000360012054,\n",
       "  0.23220000350847841,\n",
       "  0.23120000349357725,\n",
       "  0.22820000344887376,\n",
       "  0.22920000346377492,\n",
       "  0.23310000352561475,\n",
       "  0.23210000351071358,\n",
       "  0.23700000358745454,\n",
       "  0.2380000036023557,\n",
       "  0.23900000361725687,\n",
       "  0.23700000358745454,\n",
       "  0.23890000361949204,\n",
       "  0.2399000036343932,\n",
       "  0.23890000361949204,\n",
       "  0.2379000036045909,\n",
       "  0.24090000364929437,\n",
       "  0.2379000036045909,\n",
       "  0.23780000360682607,\n",
       "  0.23880000362172724,\n",
       "  0.24080000365152954,\n",
       "  0.23580000357702374,\n",
       "  0.23190000351518392,\n",
       "  0.2379000036045909,\n",
       "  0.23090000350028275,\n",
       "  0.22990000348538162,\n",
       "  0.22780000345781445,\n",
       "  0.22880000347271562,\n",
       "  0.22280000338330866,\n",
       "  0.22580000342801212,\n",
       "  0.22580000342801212,\n",
       "  0.22580000342801212,\n",
       "  0.22580000342801212,\n",
       "  0.22480000341311096,\n",
       "  0.22780000345781445,\n",
       "  0.22880000347271562,\n",
       "  0.22480000341311096,\n",
       "  0.22080000335350633,\n",
       "  0.2158000032790005,\n",
       "  0.21480000326409937,\n",
       "  0.21870000332593917,\n",
       "  0.23270000353455544,\n",
       "  0.23470000356435775,\n",
       "  0.23670000359416007,\n",
       "  0.24070000365376473,\n",
       "  0.2417000036686659,\n",
       "  0.2467000037431717,\n",
       "  0.24570000372827053,\n",
       "  0.2467000037431717,\n",
       "  0.24960000379011035,\n",
       "  0.24960000379011035,\n",
       "  0.2515000038221478,\n",
       "  0.252500003837049,\n",
       "  0.2544000038690865,\n",
       "  0.2593000039458275,\n",
       "  0.256300003901124,\n",
       "  0.2613000039756298,\n",
       "  0.26430000402033327,\n",
       "  0.26030000396072867,\n",
       "  0.2594000039435923,\n",
       "  0.26140000397339463,\n",
       "  0.26340000400319696,\n",
       "  0.2644000040180981,\n",
       "  0.2673000040650368,\n",
       "  0.2743000041693449,\n",
       "  0.2743000041693449,\n",
       "  0.27830000422894957,\n",
       "  0.28030000425875184,\n",
       "  0.28130000427365304,\n",
       "  0.28030000425875184,\n",
       "  0.28130000427365304,\n",
       "  0.2843000043183565,\n",
       "  0.2843000043183565,\n",
       "  0.2843000043183565,\n",
       "  0.28330000430345537,\n",
       "  0.28630000434815883,\n",
       "  0.2844000042974949,\n",
       "  0.2774000041931868,\n",
       "  0.2814000042527914,\n",
       "  0.2795000042207539,\n",
       "  0.2755000041611493,\n",
       "  0.2746000041440129,\n",
       "  0.2745000041648746,\n",
       "  0.2745000041648746,\n",
       "  0.27840000422671435,\n",
       "  0.27440000416710975,\n",
       "  0.2774000042118132,\n",
       "  0.27840000422671435,\n",
       "  0.2774000042118132,\n",
       "  0.28130000427365304,\n",
       "  0.2912000044248998,\n",
       "  0.29330000445246696,\n",
       "  0.2923000044375658,\n",
       "  0.28940000439062713,\n",
       "  0.288400004375726,\n",
       "  0.2944000044651329,\n",
       "  0.2984000045247376,\n",
       "  0.30440000461414457,\n",
       "  0.30440000461414457,\n",
       "  0.3064000046439469,\n",
       "  0.31240000473335383,\n",
       "  0.3153000047802925,\n",
       "  0.31730000481009485,\n",
       "  0.3203000048547983,\n",
       "  0.3233000048995018,\n",
       "  0.32130000486969945,\n",
       "  0.31730000481009485,\n",
       "  0.318300004824996,\n",
       "  0.31540000477805735,\n",
       "  0.3164000047929585,\n",
       "  0.31630000479519366,\n",
       "  0.3193000048398972,\n",
       "  0.3184000048227608,\n",
       "  0.32040000485256315,\n",
       "  0.3214000048674643,\n",
       "  0.3224000048823655,\n",
       "  0.3224000048823655,\n",
       "  0.3234000048972666,\n",
       "  0.3275000049546361,\n",
       "  0.32950000498443843,\n",
       "  0.32850000496953724,\n",
       "  0.33650000508874656,\n",
       "  0.33550000507384536,\n",
       "  0.32950000498443843,\n",
       "  0.33150000501424076,\n",
       "  0.3316000050120056,\n",
       "  0.33170000500977037,\n",
       "  0.32770000495016577,\n",
       "  0.32570000492036344,\n",
       "  0.32070000484585764,\n",
       "  0.32660000493749974,\n",
       "  0.3275000049546361,\n",
       "  0.34150000516325235,\n",
       "  0.3385000051185489,\n",
       "  0.3345000050589442,\n",
       "  0.3325000050291419,\n",
       "  0.3325000050291419,\n",
       "  0.3385000051185489,\n",
       "  0.3375000051036477,\n",
       "  0.33950000513345,\n",
       "  0.3366000050865114,\n",
       "  0.3286000049673021,\n",
       "  0.3256000049225986,\n",
       "  0.32350000489503145,\n",
       "  0.3225000048801303,\n",
       "  0.3195000048354268,\n",
       "  0.31850000482052565,\n",
       "  0.31850000482052565,\n",
       "  0.3165000047907233,\n",
       "  0.31560000477358696,\n",
       "  0.3155000047758222,\n",
       "  0.3196000048331916,\n",
       "  0.3196000048331916,\n",
       "  0.316700004786253,\n",
       "  0.3167000048048794,\n",
       "  0.3157000047899783,\n",
       "  0.3147000047750771,\n",
       "  0.31270000474527476,\n",
       "  0.32060000486671925,\n",
       "  0.3205000048689544,\n",
       "  0.3205000048689544,\n",
       "  0.3195000048540533,\n",
       "  0.32250000489875674,\n",
       "  0.32060000486671925,\n",
       "  0.31260000474750993,\n",
       "  0.3136000047624111,\n",
       "  0.3136000047624111,\n",
       "  0.3116000047326088,\n",
       "  0.30960000470280646,\n",
       "  0.30960000470280646,\n",
       "  0.306600004658103,\n",
       "  0.306600004658103,\n",
       "  0.31260000474750993,\n",
       "  0.3235000049136579,\n",
       "  0.3235000049136579,\n",
       "  0.3195000048540533,\n",
       "  0.3205000048689544,\n",
       "  0.3274000049754977,\n",
       "  0.3224000049009919,\n",
       "  0.32640000496059657,\n",
       "  0.32940000500530003,\n",
       "  0.3304000050202012,\n",
       "  0.33150000501424076,\n",
       "  0.32950000498443843,\n",
       "  0.3265000049397349,\n",
       "  0.3294000049866736,\n",
       "  0.32740000495687127,\n",
       "  0.33240000503137707,\n",
       "  0.3404000051505864,\n",
       "  0.3385000051185489,\n",
       "  0.33260000502690673,\n",
       "  0.33260000502690673,\n",
       "  0.3335000050440431,\n",
       "  0.3335000050440431,\n",
       "  0.3325000050291419,\n",
       "  0.3325000050291419,\n",
       "  0.3294000049866736,\n",
       "  0.32930000498890877,\n",
       "  0.32930000498890877,\n",
       "  0.3253000049293041,\n",
       "  0.318300004824996,\n",
       "  0.31540000477805735,\n",
       "  0.3174000048078597,\n",
       "  0.3114000047184527,\n",
       "  0.31240000473335383,\n",
       "  0.313400004748255,\n",
       "  0.31350000474601986,\n",
       "  0.31350000474601986,\n",
       "  0.31350000474601986,\n",
       "  0.31050000470131633,\n",
       "  0.31160000471398236,\n",
       "  0.30860000466927884,\n",
       "  0.30660000463947656,\n",
       "  0.30560000462457537,\n",
       "  0.30460000460967424,\n",
       "  0.30460000460967424,\n",
       "  0.3016000045649707,\n",
       "  0.2966000044904649,\n",
       "  0.2916000044159591,\n",
       "  0.2896000043861568,\n",
       "  0.28760000435635447,\n",
       "  0.2796000042371452,\n",
       "  0.2836000042967498,\n",
       "  0.28560000432655214,\n",
       "  0.2836000042967498,\n",
       "  0.284600004311651,\n",
       "  0.2896000043861568,\n",
       "  0.29060000440105793,\n",
       "  0.2916000044159591,\n",
       "  0.2956000044755638,\n",
       "  0.2927000044286251,\n",
       "  0.2927000044286251,\n",
       "  0.27970000423491004,\n",
       "  0.2807000042498112,\n",
       "  0.27970000423491004,\n",
       "  0.2877000043541193,\n",
       "  0.2927000044286251,\n",
       "  0.2977000045031309,\n",
       "  0.2996000045351684,\n",
       "  0.2996000045351684,\n",
       "  0.29860000452026725,\n",
       "  0.2956000044755638,\n",
       "  0.2966000044904649,\n",
       "  0.2927000044286251,\n",
       "  0.2927000044286251,\n",
       "  0.2987000045180321,\n",
       "  0.2947000044584274,\n",
       "  0.2997000045329332,\n",
       "  0.30270000457763674,\n",
       "  0.30470000460743907,\n",
       "  0.3038000045903027,\n",
       "  0.3007000045478344,\n",
       "  0.2987000045180321,\n",
       "  0.2997000045329332,\n",
       "  0.30180000454187395,\n",
       "  0.30080000452697275,\n",
       "  0.29580000445246696,\n",
       "  0.2988000044971704,\n",
       "  0.29490000443533065,\n",
       "  0.29700000446289776,\n",
       "  0.29700000446289776,\n",
       "  0.2960000044479966,\n",
       "  0.29300000440329316,\n",
       "  0.29800000447779895,\n",
       "  0.3029000045545399,\n",
       "  0.29990000450983645,\n",
       "  0.2959000044502318,\n",
       "  0.30080000452697275,\n",
       "  0.3108000046759844,\n",
       "  0.3128000047057867,\n",
       "  0.314800004735589,\n",
       "  0.314800004735589,\n",
       "  0.3098000046610832,\n",
       "  0.29890000449493526,\n",
       "  0.3139000047184527,\n",
       "  0.315900004748255,\n",
       "  0.31790000477805735,\n",
       "  0.3269000049121678,\n",
       "  0.3309000049717724,\n",
       "  0.32890000494197014,\n",
       "  0.33390000501647593,\n",
       "  0.33490000503137707,\n",
       "  0.33290000500157474,\n",
       "  0.33590000504627826,\n",
       "  0.33600000504404304,\n",
       "  0.3381000050716102,\n",
       "  0.34210000513121486,\n",
       "  0.3381000050716102,\n",
       "  0.33010000495240094,\n",
       "  0.32910000493749975,\n",
       "  0.3311000049673021,\n",
       "  0.3271000049076974,\n",
       "  0.3252000048756599,\n",
       "  0.3312000049650669,\n",
       "  0.33020000495016577,\n",
       "  0.32820000492036344,\n",
       "  0.3293000049330294,\n",
       "  0.3274000049009919,\n",
       "  0.3334000049903989,\n",
       "  0.3373000050522387,\n",
       "  0.33630000503733753,\n",
       "  0.33830000506713986,\n",
       "  0.33330000499263407,\n",
       "  0.3403000050969422,\n",
       "  0.3473000052012503,\n",
       "  0.345300005171448,\n",
       "  0.3503000052459538,\n",
       "  0.3503000052459538,\n",
       "  0.3553000053204596,\n",
       "  0.35930000538006424,\n",
       "  0.3583000053651631,\n",
       "  0.36430000545457003,\n",
       "  0.3743000056035817,\n",
       "  0.37230000557377935,\n",
       "  0.3863000057823956,\n",
       "  0.39630000593140724,\n",
       "  0.3983000059612095,\n",
       "  0.40230000602081417,\n",
       "  0.40630000608041883,\n",
       "  0.4103000061400235,\n",
       "  0.41330000618472695,\n",
       "  0.4153000062145293,\n",
       "  0.4153000062145293,\n",
       "  0.4173000062443316,\n",
       "  0.4203000062890351,\n",
       "  0.41930000627413394,\n",
       "  0.4123000061698258,\n",
       "  0.4113000061549246,\n",
       "  0.4093000061251223,\n",
       "  0.40730000609531997,\n",
       "  0.40420000605285167,\n",
       "  0.4093000061251223,\n",
       "  0.4143000061996281,\n",
       "  0.4153000062145293,\n",
       "  0.4173000062443316,\n",
       "  0.4273000063933432,\n",
       "  0.42630000637844206,\n",
       "  0.44130000660195945,\n",
       "  0.44040000658482314,\n",
       "  0.464400006942451,\n",
       "  0.464400006942451,\n",
       "  0.46240000691264865,\n",
       "  0.46240000691264865,\n",
       "  0.47340000707656144,\n",
       "  0.47840000715106723,\n",
       "  0.47840000715106723,\n",
       "  0.4834000072255731,\n",
       "  0.4834000072255731,\n",
       "  0.48040000718086956,\n",
       "  0.48940000731498,\n",
       "  0.4884000073000789,\n",
       "  0.4855000072531402,\n",
       "  0.49250000735744837,\n",
       "  0.49240000735968353,\n",
       "  0.4863000072725117,\n",
       "  0.4973000074364245,\n",
       "  0.506300007570535])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = MAgent(state_size, action_size, 42, num_agents=num_agents)\n",
    "run_ddpg_multi(agent, n_episodes=5000, queue=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from maddpg import MAgent\n",
    "from importlib import reload\n",
    "import maddpg\n",
    "maddpg = reload(maddpg)\n",
    "MAgent = maddpg.MAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = MAgent(state_size, action_size, 42, num_agents=num_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]      \n",
    "states = env_info.vector_observations\n",
    "agent.reset() # Resets the noise\n",
    "scores = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#while True:\n",
    "for _ in range(500):\n",
    "    actions = agent.act(states, add_noise=True)\n",
    "    # Take a step in the environment\n",
    "    env_info = env.step(actions)[brain_name]\n",
    "    # What do we get with the step\n",
    "    next_states = env_info.vector_observations        \n",
    "    rewards = env_info.rewards                         \n",
    "    dones = env_info.local_done\n",
    "    # Tell the agent\n",
    "    #for i in range(2):\n",
    "    #    agent.agents[i].memory.add(states[i], actions[i], rewards[i], next_states[i], dones[i])\n",
    "    agent.step(states, actions, rewards, next_states, dones)\n",
    "    scores += rewards                                  \n",
    "    states = next_states                               \n",
    "    if np.any(dones):                                  \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<maddpg.ReplayBuffer at 0x7fe8fe05af60>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_agent = MAgent(state_size, action_size, 42, num_agents=num_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]     # reset the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_info.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = env_info.vector_observations                  # get the current state (for each agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.shape # state size is 8 but then stack on 3 so get 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.random.randn(num_agents, action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.59609264,  0.66533179],\n",
       "       [ 1.46914752, -2.76437587]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.clip(actions, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.59609264,  0.66533179],\n",
       "       [ 1.        , -1.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = torch.from_numpy(states).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = []\n",
    "for i in range(2):\n",
    "    agent = ma_agent.agents[i]\n",
    "    agent.actor_local.eval()\n",
    "    with torch.no_grad():\n",
    "        action = agent.actor_local(states[i].unsqueeze(0)).cpu().data.numpy().squeeze()\n",
    "    agent.actor_local.train()\n",
    "    actions.append(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(actions).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_agent.noise.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.00000e-02 *\n",
       "       [[-1.0191,  1.3385],\n",
       "        [-1.0034,  1.5844]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ma_agent.agents[0].actor_local(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size [1, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-416c77e4444c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mma_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/envs/drlnd/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/ABD/Areas/Learn/udacity_rl/p3_collab-compet/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;34m\"\"\"Build an actor (policy) network that maps states -> actions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/drlnd/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/drlnd/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     47\u001b[0m         return F.batch_norm(\n\u001b[1;32m     48\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             self.training or not self.track_running_stats, self.momentum, self.eps)\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/drlnd/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected more than 1 value per channel when training, got input size {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1193\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size [1, 256]"
     ]
    }
   ],
   "source": [
    "agent.actor_local.eval()\n",
    "ma_agent.agents[0].actor_local(states[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 48])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((torch.from_numpy(states), torch.from_numpy(states)), dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -7.98256969, -1.5       , -0.        ,  0.        ,\n",
       "        -7.11741829,  5.91759634, -0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -7.40637112, -1.5       ,  0.        ,  0.        ,\n",
       "         7.11741829,  5.91759634,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_agent.agents[0].memory.add(states[0], actions[0], rewards[0], next_states[0], dones[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:drlnd]",
   "language": "python",
   "name": "conda-env-drlnd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
